#[derive(Debug, Clone, PartialEq)]
pub enum Token {
    æ•°å€¤(f64), // ğŸŒŸ ã“ã“ãŒä¿®æ­£ãƒã‚¤ãƒ³ãƒˆï¼æ­£ã—ã„ã€Œå€¤ã€ã«ãªã£ã¦ã„ã¾ã™
    æ–‡å­—åˆ—(String),
    è­˜åˆ¥å­(String),
    
    // ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    ã‚‚ã—, ãªã‚‰ã°, ã•ã‚‚ãªãã°, ç¹°è¿”,
    è¡¨ç¤º, çµ‚ã‚ã‚Š, è¨˜éŒ², é€ä¿¡,
    å¤‰æ•°,
    æ™‚åˆ», æ—¥æ™‚, æ›œæ—¥,

    // è¨˜å·
    ç­‰å·,       // =
    å¤§ãªã‚Š,     // >
    å°ãªã‚Š,     // <
    åŠ ç®—,       // +
    æ¸›ç®—,       // -
    ä¹—ç®—,       // *
    é™¤ç®—,       // /
    å·¦æ‹¬å¼§,     // (
    å³æ‹¬å¼§,     // )
    å·¦ä¸­æ‹¬å¼§,   // {
    å³ä¸­æ‹¬å¼§,   // }
    
    çµ‚ç«¯,       // EOF
}

pub struct Lexer {
    input: Vec<char>,
    pub position: usize,
}

impl Lexer {
    pub fn new(input: &str) -> Self {
        Self {
            input: input.chars().collect(),
            position: 0,
        }
    }

    pub fn æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å‡ºã™(&mut self) -> Token {
        self.ç©ºç™½ã‚’ã‚¹ã‚­ãƒƒãƒ—();

        if self.position >= self.input.len() {
            return Token::çµ‚ç«¯;
        }

        let ch = self.input[self.position];

        // ã‚³ãƒ¡ãƒ³ãƒˆï¼ˆ#ï¼‰ã‚¹ã‚­ãƒƒãƒ—å‡¦ç†
        if ch == '#' {
            self.ã‚³ãƒ¡ãƒ³ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—();
            return self.æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å‡ºã™();
        }

        // æ•°å­—
        if ch.is_digit(10) || "ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™".contains(ch) {
            return self.æ•°å€¤ã‚’èª­ã‚€();
        }

        // æ–‡å­—åˆ—
        if ch == 'ã€Œ' {
            return self.æ–‡å­—åˆ—ã‚’èª­ã‚€();
        }

        // è­˜åˆ¥å­ãƒ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        if Self::is_identifier_start(ch) {
            let ident = self.è­˜åˆ¥å­ã‚’èª­ã‚€();
            return match ident.as_str() {
                "ã‚‚ã—" => Token::ã‚‚ã—,
                "æ™‚åˆ»" | "ã„ã¾" => Token::æ™‚åˆ»,
                "æ—¥æ™‚" | "æ—¥ä»˜" => Token::æ—¥æ™‚,
                "æ›œæ—¥" | "ã‚ˆã†ã³" => Token::æ›œæ—¥,
                "ãªã‚‰ã°" | "ãªã‚‰" => Token::ãªã‚‰ã°,
                "ã•ã‚‚ãªãã°" | "ã§ãªã‘ã‚Œã°" => Token::ã•ã‚‚ãªãã°,
                "ç¹°ã‚Šè¿”ã™" | "ç¹°è¿”" | "ãšã£ã¨" => Token::ç¹°è¿”,
                "è¡¨ç¤º" | "è¨€ã†" => Token::è¡¨ç¤º,
                "çµ‚ã‚ã‚Š" | "ä»¥ä¸Š" | "ãŠã‚ã‚Š" => Token::çµ‚ã‚ã‚Š,
                "è¨˜éŒ²" | "ã‚»ãƒ¼ãƒ–" | "ã‚³ãƒŸãƒƒãƒˆ" => Token::è¨˜éŒ²,
                "é€ä¿¡" | "ãƒ—ãƒƒã‚·ãƒ¥" => Token::é€ä¿¡,
                "å¤‰æ•°" | "ç®±" => Token::å¤‰æ•°,
                _ => Token::è­˜åˆ¥å­(ident),
            };
        }

        // è¨˜å·
        match ch {
            '=' | 'ï¼' => { self.position += 1; Token::ç­‰å· },
            '+' | 'ï¼‹' => { self.position += 1; Token::åŠ ç®— },
            '-' | 'ãƒ¼' => { self.position += 1; Token::æ¸›ç®— },
            '*' | 'Ã—' => { self.position += 1; Token::ä¹—ç®— },
            '/' | 'Ã·' => { self.position += 1; Token::é™¤ç®— },
            '>' | 'ï¼' => { self.position += 1; Token::å¤§ãªã‚Š },
            '<' | 'ï¼œ' => { self.position += 1; Token::å°ãªã‚Š },
            '(' | 'ï¼ˆ' => { self.position += 1; Token::å·¦æ‹¬å¼§ },
            ')' | 'ï¼‰' => { self.position += 1; Token::å³æ‹¬å¼§ },
            '{' | 'ï½›' => { self.position += 1; Token::å·¦ä¸­æ‹¬å¼§ },
            '}' | 'ï½' => { self.position += 1; Token::å³ä¸­æ‹¬å¼§ },
            _ => {
                self.position += 1;
                self.æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å‡ºã™()
            }
        }
    }

    fn ç©ºç™½ã‚’ã‚¹ã‚­ãƒƒãƒ—(&mut self) {
        while self.position < self.input.len() {
            let ch = self.input[self.position];
            if ch == ' ' || ch == '\t' || ch == '\n' || ch == '\r' || ch == 'ã€€' {
                self.position += 1;
            } else {
                break;
            }
        }
    }

    fn ã‚³ãƒ¡ãƒ³ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—(&mut self) {
        while self.position < self.input.len() {
            if self.input[self.position] == '\n' {
                break;
            }
            self.position += 1;
        }
    }

    fn æ•°å€¤ã‚’èª­ã‚€(&mut self) -> Token {
        let start = self.position;
        while self.position < self.input.len() {
            let ch = self.input[self.position];
            if ch.is_digit(10) || ch == '.' || "ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï¼".contains(ch) {
                self.position += 1;
            } else {
                break;
            }
        }
        let s: String = self.input[start..self.position].iter().collect();
        let normalized: String = s.chars().map(|c| match c {
            'ï¼'..='ï¼™' => char::from_u32(c as u32 - 'ï¼' as u32 + '0' as u32).unwrap(),
            'ï¼' => '.',
            _ => c,
        }).collect();
        let n = normalized.parse().unwrap_or(0.0);
        Token::æ•°å€¤(n)
    }

    fn æ–‡å­—åˆ—ã‚’èª­ã‚€(&mut self) -> Token {
        self.position += 1; // ã€Œ
        let start = self.position;
        while self.position < self.input.len() && self.input[self.position] != 'ã€' {
            self.position += 1;
        }
        let s: String = self.input[start..self.position].iter().collect();
        if self.position < self.input.len() {
             self.position += 1; // ã€
        }
        Token::æ–‡å­—åˆ—(s)
    }

    fn è­˜åˆ¥å­ã‚’èª­ã‚€(&mut self) -> String {
        let start = self.position;
        while self.position < self.input.len() {
            let ch = self.input[self.position];
            if Self::is_identifier_char(ch) {
                self.position += 1;
            } else {
                break;
            }
        }
        self.input[start..self.position].iter().collect()
    }

    fn is_identifier_start(ch: char) -> bool {
        !ch.is_digit(10) && !"# ã€Œã€=+-*/><(){}\t\n\rã€€ï¼ï¼‹ãƒ¼Ã—Ã·ï¼ï¼œï¼ˆï¼‰ï½›ï½".contains(ch)
    }

    fn is_identifier_char(ch: char) -> bool {
        !ch.is_whitespace() && !"# ã€Œã€=+-*/><(){}\t\n\rã€€ï¼ï¼‹ãƒ¼Ã—Ã·ï¼ï¼œï¼ˆï¼‰ï½›ï½".contains(ch)
    }
}